{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization on CIFAR-10\n",
    "\n",
    "In this notebook we implement batch normalization, which is an opimization method useful for deep feed-forward neural networks, such as deep CNNs. Here we implement it on a toy-model of fully-connected (dense) layers, and toy-data (CIFAR-10).\n",
    "\n",
    "In addition to Batch Normalization, we demonstrate how to implement early stopping, saving a checkpoint model, and use Keras logging for Tensorboard. \n",
    "\n",
    "The main takeaways from this notebook are to know how to implement in Keras:\n",
    "1. Batch Normalization\n",
    "2. Early Stopping\n",
    "3. Saving Checkpoints\n",
    "4. Default Keras Logs into Tensorboard\n",
    "\n",
    "Based on the [notebook](https://github.com/ageron/handson-ml3/blob/main/11_training_deep_neural_networks.ipynb) of Geron, chapter 11, exercise 8.\n",
    "Presented here in accordance with the Apache 2.0 license. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "CIFAR-10 dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes (for students: what is the difference between CIFAR-10 and MNIST in that sense?).\n",
    "\n",
    "We get the data from tf.keras.datasets (similar to how we did for MNIST). This means that we get numpy array back. \n",
    "\n",
    "As seen in the [dataset description](https://keras.io/api/datasets/cifar10/), the 10 classes are:\n",
    "\n",
    "Label |\tDescription\n",
    "--- | ---\n",
    "0 |\tairplane\n",
    "1 |\tautomobile\n",
    "2 |\tbird\n",
    "3 |\tcat\n",
    "4 |\tdeer\n",
    "5 |\tdog\n",
    "6 |\tfrog\n",
    "7 |\thorse\n",
    "8 |\tship\n",
    "9 |\ttruck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 15s 0us/step\n"
     ]
    }
   ],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10\n",
    "\n",
    "# TODO: for the students: how many images are there in the training and the validation sets?\n",
    "# TODO: for the students: what does 'x' and 'y' stand for?\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x241c135d840>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: for the students: which additional data explorations would you do?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Base Model\n",
    "Here we build a DNN with 20 hidden layers of 100 neurons each. \n",
    "That's too many, but it's the point of this exercise, because it allows us to use some of the optimization techniques we learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: for the students: can you add comments to each line of code below explaining what it does and why?\n",
    "\n",
    "# ?\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ?\n",
    "model = tf.keras.Sequential()\n",
    "# ?\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "# ?\n",
    "for _ in range(20):\n",
    "    # ?\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    # ?\n",
    "                                    activation=\"swish\",\n",
    "                                    # ? \n",
    "                                    kernel_initializer=\"he_normal\"))\n",
    "# ?\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Loss Function, Optimizer and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Callbacks for Early Stopping, Checkpoints, and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cifar10_model\",\n",
    "                                                         save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = f\"./runs/cifar10_logs/run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traing the Model\n",
    "Before start running the training, initialize Tensorboard, such that you can view the training as it progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 8.2860 - accuracy: 0.1004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 17s 8ms/step - loss: 8.2863 - accuracy: 0.1003 - val_loss: 8.1452 - val_accuracy: 0.0972\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 8.2026 - accuracy: 0.1003 - val_loss: 9.7473 - val_accuracy: 0.0972\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 9.7007 - accuracy: 0.1003 - val_loss: 9.7473 - val_accuracy: 0.0972\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 9.7007 - accuracy: 0.1003 - val_loss: 9.7473 - val_accuracy: 0.0970\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 9.7007 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 9.7003 - accuracy: 0.1003 - val_loss: 9.7472 - val_accuracy: 0.0972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241cc206410>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 2.0596 - accuracy: 0.2446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 30s 13ms/step - loss: 2.0592 - accuracy: 0.2447 - val_loss: 1.8729 - val_accuracy: 0.3244\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.7832 - accuracy: 0.3565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.7832 - accuracy: 0.3565 - val_loss: 1.8135 - val_accuracy: 0.3414\n",
      "Epoch 3/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.6860 - accuracy: 0.3997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6860 - accuracy: 0.3997 - val_loss: 1.6883 - val_accuracy: 0.3830\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6171 - accuracy: 0.4231 - val_loss: 1.7486 - val_accuracy: 0.3808\n",
      "Epoch 5/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5609 - accuracy: 0.4447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5610 - accuracy: 0.4447 - val_loss: 1.5807 - val_accuracy: 0.4320\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5140 - accuracy: 0.4638 - val_loss: 1.7323 - val_accuracy: 0.3884\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4638 - accuracy: 0.4790 - val_loss: 1.6086 - val_accuracy: 0.4216\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4252 - accuracy: 0.4965 - val_loss: 1.7078 - val_accuracy: 0.3994\n",
      "Epoch 9/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.3954 - accuracy: 0.5075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 26s 18ms/step - loss: 1.3952 - accuracy: 0.5076 - val_loss: 1.4378 - val_accuracy: 0.4818\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3603 - accuracy: 0.5170 - val_loss: 1.4825 - val_accuracy: 0.4752\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3320 - accuracy: 0.5276 - val_loss: 1.5133 - val_accuracy: 0.4770\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 18s 12ms/step - loss: 1.3041 - accuracy: 0.5368 - val_loss: 1.6617 - val_accuracy: 0.4166\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2786 - accuracy: 0.5451 - val_loss: 1.5835 - val_accuracy: 0.4548\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2536 - accuracy: 0.5569 - val_loss: 1.5254 - val_accuracy: 0.4780\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2278 - accuracy: 0.5642 - val_loss: 1.5365 - val_accuracy: 0.4670\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2151 - accuracy: 0.5708 - val_loss: 1.5132 - val_accuracy: 0.4714\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1901 - accuracy: 0.5791 - val_loss: 1.4787 - val_accuracy: 0.4944\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1693 - accuracy: 0.5866 - val_loss: 1.5302 - val_accuracy: 0.4672\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1546 - accuracy: 0.5925 - val_loss: 1.5322 - val_accuracy: 0.4678\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1355 - accuracy: 0.6014 - val_loss: 1.6706 - val_accuracy: 0.4408\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1190 - accuracy: 0.6056 - val_loss: 1.6045 - val_accuracy: 0.4640\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1012 - accuracy: 0.6116 - val_loss: 1.6348 - val_accuracy: 0.4722\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0866 - accuracy: 0.6168 - val_loss: 1.4389 - val_accuracy: 0.5122\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0705 - accuracy: 0.6224 - val_loss: 1.5254 - val_accuracy: 0.4914\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0584 - accuracy: 0.6267 - val_loss: 1.5447 - val_accuracy: 0.4776\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0456 - accuracy: 0.6312 - val_loss: 1.4529 - val_accuracy: 0.5056\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0300 - accuracy: 0.6385 - val_loss: 1.4920 - val_accuracy: 0.4982\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0230 - accuracy: 0.6423 - val_loss: 1.5216 - val_accuracy: 0.4996\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0125 - accuracy: 0.6426 - val_loss: 1.5578 - val_accuracy: 0.4918\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.4378 - accuracy: 0.4818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4378284215927124, 0.48179998993873596]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())  # Adding batch normalization\n",
    "    model.add(tf.keras.layers.Activation(\"swish\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cifar10_bn_model\",\n",
    "                                                         save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = f\"cifar10_logs/run_bn_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "tensorflow_cpu"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea445e1515f943d2885e4730ea69ace15b02c78ac5cd5be2a495018cd89fb42d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
