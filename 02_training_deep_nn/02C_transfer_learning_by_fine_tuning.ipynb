{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "The data:\n",
    "https://keras.io/api/datasets/fashion_mnist/\n",
    "\n",
    "Fashion-MNIST is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST.\n",
    "\n",
    "The classes are:\n",
    "\n",
    "Label |\tDescription\n",
    "--- | ---\n",
    "0|\tT-shirt/top\n",
    "1|\tTrouser\n",
    "2|\tPullover\n",
    "3|\tDress\n",
    "4|\tCoat\n",
    "5|\tSandal\n",
    "6|\tShirt\n",
    "7|\tSneaker\n",
    "8|\tBag\n",
    "9|\tAnkle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13302532050>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255\n",
    "\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for **T-shirts/tops** and **pullovers** (classes **0** and **2**).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of T-shirts/tops and pullovers.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (trousers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots) are somewhat similar to classes in set B (T-shirts/tops and pullovers). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class_id = class_names.index(\"Pullover\")\n",
    "neg_class_id = class_names.index(\"T-shirt/top\")\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
    "    y_A = y[~y_for_B]\n",
    "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
    "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
    "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
    "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
    "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1376/1376 [==============================] - 2s 2ms/step - loss: 1.1036 - accuracy: 0.6690 - val_loss: 0.6762 - val_accuracy: 0.7869\n",
      "Epoch 2/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.5874 - accuracy: 0.8155 - val_loss: 0.5019 - val_accuracy: 0.8403\n",
      "Epoch 3/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.4739 - accuracy: 0.8514 - val_loss: 0.4325 - val_accuracy: 0.8611\n",
      "Epoch 4/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.4175 - accuracy: 0.8639 - val_loss: 0.3915 - val_accuracy: 0.8721\n",
      "Epoch 5/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.3822 - accuracy: 0.8741 - val_loss: 0.3656 - val_accuracy: 0.8754\n",
      "Epoch 6/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.3580 - accuracy: 0.8799 - val_loss: 0.3469 - val_accuracy: 0.8807\n",
      "Epoch 7/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.3403 - accuracy: 0.8844 - val_loss: 0.3337 - val_accuracy: 0.8837\n",
      "Epoch 8/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.3263 - accuracy: 0.8885 - val_loss: 0.3262 - val_accuracy: 0.8854\n",
      "Epoch 9/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.3155 - accuracy: 0.8932 - val_loss: 0.3145 - val_accuracy: 0.8907\n",
      "Epoch 10/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.3057 - accuracy: 0.8952 - val_loss: 0.3104 - val_accuracy: 0.8942\n",
      "Epoch 11/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2976 - accuracy: 0.8979 - val_loss: 0.3023 - val_accuracy: 0.8965\n",
      "Epoch 12/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2907 - accuracy: 0.9007 - val_loss: 0.3021 - val_accuracy: 0.8945\n",
      "Epoch 13/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2850 - accuracy: 0.9020 - val_loss: 0.2937 - val_accuracy: 0.8982\n",
      "Epoch 14/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2790 - accuracy: 0.9047 - val_loss: 0.2866 - val_accuracy: 0.8982\n",
      "Epoch 15/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2742 - accuracy: 0.9057 - val_loss: 0.2824 - val_accuracy: 0.9030\n",
      "Epoch 16/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2695 - accuracy: 0.9077 - val_loss: 0.2786 - val_accuracy: 0.9022\n",
      "Epoch 17/20\n",
      "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2653 - accuracy: 0.9090 - val_loss: 0.2757 - val_accuracy: 0.9052\n",
      "Epoch 18/20\n",
      "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2607 - accuracy: 0.9104 - val_loss: 0.2717 - val_accuracy: 0.9060\n",
      "Epoch 19/20\n",
      "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2574 - accuracy: 0.9119 - val_loss: 0.2711 - val_accuracy: 0.9065\n",
      "Epoch 20/20\n",
      "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2536 - accuracy: 0.9124 - val_loss: 0.2713 - val_accuracy: 0.9113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_A\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_A\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_A = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                      validation_data=(X_valid_A, y_valid_A))\n",
    "model_A.save(\"my_model_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 60ms/step - loss: 0.7919 - accuracy: 0.1900 - val_loss: 0.7715 - val_accuracy: 0.2404\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7676 - accuracy: 0.2450 - val_loss: 0.7503 - val_accuracy: 0.3017\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.7453 - accuracy: 0.3200 - val_loss: 0.7322 - val_accuracy: 0.3788\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7231 - accuracy: 0.3750 - val_loss: 0.7152 - val_accuracy: 0.4392\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7053 - accuracy: 0.4800 - val_loss: 0.6969 - val_accuracy: 0.5074\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6859 - accuracy: 0.5650 - val_loss: 0.6781 - val_accuracy: 0.5776\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6659 - accuracy: 0.6550 - val_loss: 0.6597 - val_accuracy: 0.6637\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.6487 - accuracy: 0.6800 - val_loss: 0.6424 - val_accuracy: 0.7280\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6299 - accuracy: 0.7450 - val_loss: 0.6253 - val_accuracy: 0.7784\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.6120 - accuracy: 0.8000 - val_loss: 0.6079 - val_accuracy: 0.8081\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5934 - accuracy: 0.8450 - val_loss: 0.5907 - val_accuracy: 0.8269\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5751 - accuracy: 0.8850 - val_loss: 0.5732 - val_accuracy: 0.8467\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5568 - accuracy: 0.9000 - val_loss: 0.5575 - val_accuracy: 0.8576\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.5402 - accuracy: 0.9200 - val_loss: 0.5416 - val_accuracy: 0.8724\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5240 - accuracy: 0.9200 - val_loss: 0.5262 - val_accuracy: 0.8863\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5086 - accuracy: 0.9150 - val_loss: 0.5119 - val_accuracy: 0.8922\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4940 - accuracy: 0.9150 - val_loss: 0.4978 - val_accuracy: 0.9001\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.4797 - accuracy: 0.9200 - val_loss: 0.4831 - val_accuracy: 0.9100\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.4657 - accuracy: 0.9150 - val_loss: 0.4705 - val_accuracy: 0.9169\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4537 - accuracy: 0.9150 - val_loss: 0.4593 - val_accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_B = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4645513594150543, 0.9135000109672546]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try reusing the pretrained model A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = tf.keras.models.load_model(\"my_model_A\")\n",
    "model_B_on_A = tf.keras.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a *clone* of `model_A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_A_clone = tf.keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "\n",
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 63ms/step - loss: 2.6119 - accuracy: 0.4450 - val_loss: 1.8199 - val_accuracy: 0.4837\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.5203 - accuracy: 0.4550 - val_loss: 1.0214 - val_accuracy: 0.5104\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9013 - accuracy: 0.5350 - val_loss: 0.7668 - val_accuracy: 0.5025\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7310 - accuracy: 0.5150 - val_loss: 0.7443 - val_accuracy: 0.4728\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 65ms/step - loss: 0.6805 - accuracy: 0.5250 - val_loss: 0.6547 - val_accuracy: 0.6044\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6006 - accuracy: 0.6550 - val_loss: 0.5858 - val_accuracy: 0.7062\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5390 - accuracy: 0.7250 - val_loss: 0.5422 - val_accuracy: 0.7438\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4800 - accuracy: 0.8050 - val_loss: 0.4905 - val_accuracy: 0.8071\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4392 - accuracy: 0.8500 - val_loss: 0.4538 - val_accuracy: 0.8437\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4096 - accuracy: 0.8750 - val_loss: 0.4255 - val_accuracy: 0.8714\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3824 - accuracy: 0.9000 - val_loss: 0.4051 - val_accuracy: 0.8764\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3677 - accuracy: 0.9100 - val_loss: 0.3822 - val_accuracy: 0.8971\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3429 - accuracy: 0.9150 - val_loss: 0.3650 - val_accuracy: 0.9021\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3278 - accuracy: 0.9200 - val_loss: 0.3524 - val_accuracy: 0.9070\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3141 - accuracy: 0.9250 - val_loss: 0.3371 - val_accuracy: 0.9130\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3006 - accuracy: 0.9350 - val_loss: 0.3243 - val_accuracy: 0.9149\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2883 - accuracy: 0.9350 - val_loss: 0.3155 - val_accuracy: 0.9238\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2798 - accuracy: 0.9300 - val_loss: 0.3068 - val_accuracy: 0.9268\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2710 - accuracy: 0.9350 - val_loss: 0.2973 - val_accuracy: 0.9298\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2625 - accuracy: 0.9350 - val_loss: 0.2895 - val_accuracy: 0.9308\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4645513594150543, 0.9135000109672546]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.9205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29749995470046997, 0.9204999804496765]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea445e1515f943d2885e4730ea69ace15b02c78ac5cd5be2a495018cd89fb42d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
